# Firebase Studio

This is a NextJS starter in Firebase Studio.

To get started, take a look at src/app/page.tsx.

---

## AI機能の仕様とトークン消費について

このアプリケーションに搭載されているAI機能（ビデオ・画像生成）には、Googleの生成AIモデルが使用されています。AIモデルの利用には、その計算処理量に応じた「トークン」が消費され、これが料金に直結します。

ユーザー体験を向上させるためにいくつかのフィードバック機能が実装されていますが、AIモデルのAPIには技術的な制約が存在します。以下にその経緯と仕様をまとめます。

### 1. AIモデルの「思考プロセス」とトークン消費

AIモデルのAPIを呼び出す（プロンプトを送信する）と、AIは応答を生成するために思考・計算処理を行います。**この思考プロセス（推論）自体がトークンの消費対象となります。**

重要なのは、**最終的なアウトプットの有無や内容に関わらず、AIが一度でも動作すればトークンは消費される**という点です。

具体的には、以下のようなケースでもトークンは消費されます。

*   **セーフティ機能が作動した場合**: プロンプトがAIの安全基準に違反すると判断され、何も生成されなかった場合でも、プロンプトを分析・判断するためのトークンが消費されます。
*   **画像に変更がなかった場合**: Image-to-Image生成において、AIが「変更を加える必要はない」と判断し、入力と全く同じ画像を返した場合でも、その結論に至るまでの思考プロセスに対してトークンが消費されます。

### 2. 「プレビュー（Dry Run）」機能は存在しない

現在の生成AIモデルのAPIには、料金を発生させずに「このプロンプトでうまくいくか」を事前に確認する**「プレビュー（Dry Run）」のような機能は存在しません。**

AIがプロンプトを評価する唯一の方法は、実際にそのプロンプトでAIを実行してみることであり、その実行自体が課金対象となります。

これはFirebase Studio（AIアシスタント）が実装しなかったのではなく、生成AIのAPIが持つ根本的な技術的制約です。

### 3. VEOモデル（ビデオ生成）におけるトークン情報の取得について

VEOモデルは、ビデオ生成という時間のかかる処理を**非同期**で行います。ユーザーがプロンプトを送信すると、まず「オペレーション（処理）」が開始され、アプリケーションはそれが完了するのを待ちます。

現在のVEOモデルのAPI仕様では、この完了したオペレーションの結果に、**消費されたトークン量（入力・出力トークン）の詳細情報が含まれていません。** そのため、画像生成（Image-to-Image）ではトークン消費量を記録できていますが、ビデオ生成においては消費量をFirestoreに記録することができません。

これもFirebase Studio側の実装の問題ではなく、VEOのAPIが持つ技術的な制約によるものです。

### 4. アプリケーションに実装済みのフィードバック機能

上記の制約の中で、ユーザーが無駄な試行を繰り返したり、予期せぬ結果に混乱したりするのを防ぐため、アプリケーションにはAIの実行結果を分析し、フィードバックを返す機能が実装されています。

*   **セーフティ機能作動の記録**: AIがコンテンツ生成をブロックした場合、その理由（`finishReason: 'SAFETY'`）と詳細な評価（`safetyRatings`）をFirestoreのメディアドキュメントに記録します。UI上でもユーザーにその旨が通知されます。

*   **「変更なし」の検知**: Image-to-Image生成において、生成前後の画像をアプリケーション側で比較します。完全に同一の画像が返された場合、「変更が検知されませんでした」というメッセージをユーザーに通知し、プロンプトの改善を促します。

これらの機能は、料金が発生した**後**に、その結果がなぜそうなったのかをユーザーが理解し、次のアクションに繋げるための補助となることを目的としています。
